---
title: "Task 3"
format: 
  html:
    code-fold: true
    embed-resources: true
execute: 
  warning: false
editor: visual
---

# Maximum Likelihoods

```{r}
library(data4led)

bulb <- led_bulb(1,seed=719) 
t <- bulb$hours
y <- bulb$percent_intensity

c.11 <- sum(t^2)
c.12 <- sum(t^3)
c.22 <- sum(t^4)
b.1 <- sum((y-100)*t)
b.2 <- sum((y-100)*t^2)
```

## Base Assumptions

These model are intended to predict the decay of light bulb brightness overtime. The decay is measured by a percentage of the original brightness of the light bulb. A light bulb is considered bad after the bulb intensity is at 80% of its original value. There are 44 points within the data set $t_i$ is represented as the number of hours that the light bulb has been on. $y_i$ is a percentage of the light bulbs original intensity. The values used in this analysis are found in the data4led package within R utilizing the seed 719.

For this analysis the assumption that the residuals are independent and normally distributed (with a mean of 0 and a standard deviation of 1) will be applied.

```{r}
pander::pander(data.frame("Function" = c("$f_1$", "$f_2$", "$f_4$", "$f_5$", "$f_6$"), "Equation" = c("$100 + 0.000204780548320951t$ where $t \ge 0$", "$f_2(t) = 100 +
(0.000641522798405015)t +(-1.1442406838189 * 10^{-7})t^2$", "$100 +  (-0.000205194652371931) t + 0.489543302990463 *  ln(0.005t + 1)$", "$100 * e^{-0.00005t} + 0.00574982239530443t e^{-0.0005t}$", "$f_6(t) = 100 + (-0.000658665767730825)t +(4.76933030173676)(1 - e^{-0.0003t})$ ")))
```

</br>

::: panel-tabset
# Function 1

**Base Function**

The function $f_1()$ is defined as: $f_1(t; a_1) = 100 + a_1t$ where $t\geq0$.

**Log Likelihood**

The loglikelihood function for the errors of this model is: $$\ell_1(a_1; \mathbf{t},\mathbf{y}) =
44\ln\left(\frac{1}{\sqrt{2\pi}}\right) - \frac{1}{2}\sum_{i}^{44} (y_i
- 100 - a_1t_i)^2$$.

**First Partial Derivative**

$\frac{\partial{l_1}}{\partial{a_1}} = (\sum^{44}_it_i(y_i-100)) - (\sum^{44}_it_i^2)a_1$

*Note: The results are below the explanation*

We first need to find the answer for each of these $(\sum^{44}_it_i(y_i-100))$ & $- (\sum^{44}_it_i^2)$. For simplicity I will refer to them in the explanation as c & d respectively. The first derivative will be set to 0 to find the value for $a_1$. The equation will be $0 = c - d * a_1$. After this you solve for $a_1$ ending with an equation like so $\frac{-c}{d} = a_1$.

```{r}
c.l1.11 <- sum(t*(y-100))
c.l1.12 <- -sum(t^2)
a.1 <- -c.l1.11/c.l1.12


pander::pander(paste0("This is the value for part c: ", c.l1.11))
pander::pander(paste0("This is the value for part d: ", c.l1.12))
pander::pander(paste0("This is the best value for $a_1$ ", a.1))

x <- seq(-10,80001,2)

f1 <- function(x=x,a1=a.1){
  y.p <- 100 + a1 * x
  return(y.p)
}


```

```{r}
y.p <- f1(x, a.1)
```

```{r}
par(mfrow=c(1,2),mar=c(2.5,2.5,1,0.25))
plot(t,y,xlab="Hour ", ylab="Intensity(%) ", pch=16,main='f1')
lines(x,f1(x, a.1),col=2)
plot(t,y,xlab="Hour ", ylab="Intensity(%) ", pch=16, xlim = c(-10,80000),ylim = c(-10,120))
lines(x,f1(x,a.1),col=2)
```

**Second Partial Derivative**

$\frac{\partial^2{l_1}}{\partial{a_1^2}} = - \sum_i^{44}t^2_i$

# Function 2

Consider the model $f_2(t; a_1, a_2) = 100 + a_1t + a_2t^2$. The function $f_2$ models the brightness of a lightbulb, measured as a percent of the original intensity of the lightbulb, given the number of hours the lightbulb as been on, t. We will fit $f_2$to the list of 44 measurements, (ti,yi), obtained from the data4led package using the seed 719.

Assuming the residuals (or errors) are independent and normally distributed (with mean 0 and standard deviation 1), the loglikelihood function for these errors is

$\ell_2(a_1,a_2; \mathbf{t},\mathbf{y}) = 44\ln\left(\frac{1}{\sqrt{2\pi}}\right) + \sum_{i=1}^{44} \left(-\frac{1}{2}(y_i - 100 - a_1t_i - a_2t_i^2)^2\right).$

We want to find the maximum of $\ell_2$. The first partials of $\ell_2$ are

-   $$\frac{\partial\ell_2}{\partial a_1} =
    \left(\sum_{i=1}^{44} (y_i - 100)t_i\right) -
    \left(\sum_{i=1}^{44}t_i^2\right)a_1 -
    \left(\sum_{i=1}^{44}t_i^3\right)a_2$$ and
-   $$\frac{\partial\ell_2}{\partial a_2} =
    \left(\sum_{i=1}^{44} (y_i - 100)t_i^2\right) -
    \left(\sum_{i=1}^{44}t_i^3\right)a_1 -
    \left(\sum_{i=1}^{44}t_i^4\right)a_2$$

To find the critical points of $\ell_2$, we set each partial derivative above equal to zero and then solve

$$\left\{
\begin{array}{ll}
\left(\sum_{i=1}^{44} (y_i - 100)t_i\right) -
\left(\sum_{i=1}^{44}t_i^2\right)a_1 -
\left(\sum_{i=1}^{44}t_i^3\right)a_2 &= 0 \\
\left(\sum_{i=1}^{44} (y_i - 100)t_i^2\right) -
\left(\sum_{i=1}^{44}t_i^3\right)a_1 -
\left(\sum_{i=1}^{44}t_i^4\right)a_2 &= 0.
\end{array}
\right.$$

We notice that this system is of the form:

$$\left\{
\begin{align*}
b_1 - c_{11}a_1 - c_{12}a_2 &= 0 \\
b_2 - c_{21}a_1 - c_{22}a_2 &= 0,
\end{align*}
\right.$$

with:

-   $$c_{11} =
    \sum_{i=1}^{44}t_i^2$$

-   $$c_{12} = c_{21} = \sum_{i=1}^{44}
    t_i^3$$

-   $$c_{22} = \sum_{i=1}^{44}
    t_i^4$$

-   $$b_1 = \sum_{i=1}^{44} (y_i -
    100)t_i$$

-   $$b_2 = \sum_{i=1}^{44} (y_i -
    100)t_i^2$$

Notice that $$\sum_{i=1}^{44} (y_i -
100)t_i$$, $\sum_{i=1}^{44}t_i^2$, $\sum_{i=1}^{44} t_i^3$, $\sum_{i=1}^{44} (y_i - 100)t_i^2$, and $\sum_{i=1}^{44} t_i^4$ are just constants that depend on the given data. We can calculate (and store) their values using the R code below.

```{r}
c.11 <- sum(t^2)
c.12 <- sum(t^3)
c.22 <- sum(t^4)
b.1 <- sum((y-100)*t)
b.2 <- sum((y-100)*t^2)
```

Since we noticed this system is of a general form we have already solved, then we can use the solution from previous work. We found that the solution to this system is

$$a_2 =
\frac{c_{11}b_2 - c_{12}b_1}{c_{11}c_{22} - c_{12}^2}\text{ and }a_1 =
\frac{b_1 - c_{12}a_2}{c_{11}}.$$ and $$a_2 =
\frac{c_{11}b_2 - c_{12}b_1}{c_{11}c_{22} - c_{12}^2}\text{ and }a_1 =
\frac{b_1 - c_{12}a_2}{c_{11}}.$$

Below we use R to calculate $a_1$ and $a_2$ using the formula above.

```{r}
best.a2 <- (c.11*b.2 - c.12*b.1)/(c.11*c.22 - c.12^2) 
best.a1 <- (b.1 - c.12*best.a2)/c.11 
pander::pander(paste0("This is the best value for $a_1$:", best.a1))
pander::pander(paste0("This is the best value for $a_2$:", best.a2))
```

The critical point for $\ell_2$ is $(a_1,a_2) = (0.000641522798405015, -1.1442406838189 \times 10^{-7}$. Let’s use the second derivative test to confirm that this critical point is the location of a maximum of $\ell_2$. The second partials of $\ell_2$are below. We will need the second partials for the second derivative test.

-   $$\frac{\partial^2\ell_2}{\partial a_1^2}
    = - \sum_{i=1}^{44}t_i^2$$

-   $$\frac{\partial^2\ell_2}{\partial a_2^2}
    = - \sum_{i=1}^{44}t_i^4$$

-   $$\frac{\partial^2\ell_2}{\partial a_2
    \partial a_1} = -\sum_{i=1}^{44}t_i^3$$

When then compute

$$D =
\left(\frac{\partial^2\ell_2}{\partial a_1^2}\right)\left(
\frac{\partial^2\ell_2}{\partial a_2^2}\right) -
\left(\frac{\partial^2\ell_2}{\partial a_2 \partial a_1}\right)^2 =
\left(- \sum_{i=1}^{44}t_i^2\right)\left(- \sum_{i=1}^{44}t_i^4\right) -
\left(- \sum_{i=1}^{44}t_i^3\right)^2.$$

To use the second derivative test, we need numerical values for both D and $\frac{\partial^2\ell_2}{\partial a_1^2}$. The code below computes both these values.

```{r}
D <- (-c.11)*(-c.22) - (-c.12)^2
pander::pander(paste0("This is the value for D:", D))
pander::pander(paste0("The second partial with respect to $a_1$ twice:", -c.11))

```

We see that $D = 1.23002961725515 \times 10^{23}$, which means D \> 0. The fact that D \> 0, together with $$\frac{\partial^2\ell_2}{\partial a_1^2} =
-3.2876753\times 10^{8}<0$$ means that our critical point corresponds to a local maximum (by the second derivative test). The completes the computations for the maximum likelihood method.

Our best fit model is

$$f_2(t) = 100 +
(0.000641522798405015)t +(-1.1442406838189\times 10^{-7})t^2$$

```{r}
f2 <- function(x,a0=0,a1=0,a2=1){
  a0 + a1*x + a2*x^2
}

a0 <- 100
a1 <- best.a1
a2 <- best.a2

x <- seq(-10,80001,2)
par(mfrow=c(1,2),mar=c(2.5,2.5,1,0.25))
plot(t,y,xlab="Hour ", ylab="Intensity(%) ", pch=16,main='f2')
lines(x,f2(x,a0,a1,a2),col=2)
plot(t,y,xlab="Hour ", ylab="Intensity(%) ", pch=16, xlim = c(-10,80000),ylim = c(-10,120))
lines(x,f2(x,a0,a1,a2),col=2)
```

Notice that the graph of the fitted function does appear to provide a good visual fit to the data, as seen in the image above. The story told by this model suggests that the light bulb will burn out (hit 80% intensity) somewhere between 10 and 20 thousand hours (we could compute this exactly with uniroot).

# Function 4

The function $f_4$ is defined as: $f_4(t; a_1,a_2) = 100 + a_1t + a_2\ln(0.005t+1)$ where $t\geq0$.

**Log Likelihood**

The loglikelihood function for the errors of this model is: $$\ell_4(a_1,a_2; \mathbf{t},\mathbf{y}) =
44\ln\left(\frac{1}{\sqrt{2\pi}}\right) - \frac{1}{2}\sum_{i}^{44} (y_i
- 100 - a_1t_i - a_2\ln(0.005t_i+1))^2$$.

**Derivatives**

::: panel-tabset
### Partial Derivatives $a_1$

**This is the first partial derivative**

$\frac{\partial{l_4}}{\partial{a_1}} = \sum_i^{44}t_i(y_i-100) - (\sum^{44}_it_i^2)a_1 - (\sum_i^{44}t_i(ln(0.00005t_i + 1)))a_2$

**This is the second partial derivative**

$\frac{\partial^2{l_4}}{\partial{a_1^2}} = -(\sum^{44}_it_i^2)$

### Partial Derivatives $a_2$

**This is the first partial derivative**

$\frac{\partial{l_4}}{\partial{a_2}} = (\sum_i^{44}(y_i-100)ln(0.0005t_i +1)) - (\sum^{44}_i t_i ln(0.0005t_i + 1))a_1 - (\sum(ln(0.0005t_i + 1))^2)a_2$

**This is the second partial derivative**

$\frac{\partial^2{l_4}}{\partial{a_2^2}} = - \sum^{44}_i(ln(0.0005t_i + 1))^2$

### Systems of Equations

For this section we will use the first derivatives with respect to $a_1$ and the first for $a_2$ respectively. Below each has been rephrased:

**For** $a_1$

$\frac{\partial{l_4}}{\partial{a_1}} = \sum_i^{44}t_i(y_i-100) - (\sum^{44}_it_i^2)a_1 - (\sum_i^{44}t_i(ln(0.0005t_i + 1)))a_2$

**For** $a_2$

$\frac{\partial{l_4}}{\partial{a_2}} = (\sum_i^{44}(y_i-100)ln(0.0005t_i +1)) - (\sum^{44}_i t_i ln(0.0005t_i + 1))a_1 - (\sum(ln(0.0005t_i + 1))^2)a_2$

For both $a_1$ and $a_2$'s first derivative we will assume each constant to be b, c (with different numeric values to differentiate) respectively. So for each equation it could be rewritten as:

$$\left\{
\begin{align*}
0 = b_1 - c_{11}*a_1 - c_{12}*a_2 \\
0 = b_2 - c_{21}*a_1 - c_{22} *a_2
\end{align*}
\right.$$

where

-   $b_1 = \sum_i^{44}t_i(y_i-100)$
-   $b_2 = (\sum_i^{44}(y_i-100)ln(0.0005t_i +1))$
-   $c_{11} = - (\sum^{44}_it_i^2)$
-   $c_{12} = - (\sum_i^{44}t_i(ln(0.0005t_i + 1)))$
-   $c_{21} = - (\sum^{44}_i t_i ln(0.0005t_i + 1))$
-   $c_{22} = - (\sum(ln(0.0005t_i + 1))^2)$

In order to find the $a_1$ & $a_2$ we can use this formula:

$a_2 =\frac{c_{11}b_2 - c_{12}b_1}{c_{11}c_{22} - c_{12}^2}\text{ and }a_1 =\frac{b_1 - c_{12}a_2}{c_{11}}$

```{r}
b.1 <- sum(t * (y - 100))
b.2 <- sum((y - 100) * log(0.005*t + 1))
c.11 <- - sum(t^2)
c.12 <- - sum(t * log(0.005 * t + 1))
c.21 <- - sum(t * log(0.005 * t + 1))
c.22 <- - sum((log(0.005 * t + 1))^2)

a2.4 <- ((c.11 * b.2) - (c.12 * b.1))/((c.11 * c.22) - (c.12^2))
a1.4 <- (b.1 - (c.12 * a2.4))/(c.11)
a1.4 <- -a1.4
a2.4 <- -a2.4

paste0("This is the best value for $a_1$:", a1.4)
paste0("This is the best value for $a_2$:", a2.4)

f4 <- function(x, a1.4, a2.4){
  y4.p <- (100 + (a1.4 * x) + (a2.4 * log((0.005 * x) + 1)))
  return(y4.p)
}

```

```{r}
par(mfrow=c(1,2),mar=c(2.5,2.5,1,0.25))
plot(t,y,xlab="Hour ", ylab="Intensity(%) ", pch=16,main='f4')
lines(x,f4(x, a1.4, a2.4),col=2)
plot(t,y,xlab="Hour ", ylab="Intensity(%) ", pch=16, xlim = c(-10,80000),ylim = c(-10,120))
lines(x,f4(x,a1.4, a2.4),col=2)
```
:::

# Function 5

The function $f_5$ is defined as: $f_5(t; a_1) = 100e^{-0.00005t} +a_1te^{-0.00005t}$ where $t\geq0$.

**Log Likelihood**

The log likelihood function for the errors of this model is: $$\ell_5(a_1; \mathbf{t},\mathbf{y}) =
44\ln\left(\frac{1}{\sqrt{2\pi}}\right) - \frac{1}{2}\sum_{i}^{44} (y_i
- 100e^{-0.00005t_i} - a_1t_ie^{-0.00005t_i})^2$$

**First Partial Derivative**

$\frac{\partial{l_5}}{\partial{a_1}} = \sum_i^{44}((y_i - 100 e^{-0.00005t_i})(t_ie^{-0.00005t_i})) - (\sum^{44}_i(t_ie^-0.00005t_i)^2)a_1$

We first need to find the answer for each of these $\sum_i^{44}((y_i - 100 e^{-0.00005t_i})(t_ie^{-0.00005t_i}))$ & $- (\sum^{44}_i(t_ie^-0.00005t_i)^2)a_1$. For simplicity I will refer to them in the explanation as c & d respectively. The first derivative will be set to 0 to find the value for $a_1$. The equation will be $0 = c - d * a_1$. After this you solve for $a_1$ ending with an equation like so $\frac{-c}{d} = a_1$.

```{r}
c.l5.11 <- sum((y - 100 * exp(-0.00005*t)) * (t*exp(-0.00005 * t)))
c.l5.12 <- -sum((t*exp((-0.00005*t)))^2)
a5.1 <- -c.l5.11/c.l5.12


pander::pander(paste0("This is the value for part c: ", c.l5.11))
pander::pander(paste0("This is the value for part d: ", c.l5.12))
pander::pander(paste0("This is the best value for $a_1$ ", a5.1))

x <- seq(-10,80001,2)

f5 <- function(x=x,a1=a5.1){
  y.p <- (100*exp(-0.00005*x)) + (a5.1 * x * exp(-0.00005*x))
  return(y.p)
}
```

```{r}
par(mfrow=c(1,2),mar=c(2.5,2.5,1,0.25))
plot(t,y,xlab="Hour ", ylab="Intensity(%) ", pch=16,main='f1')
lines(x,f5(x, a5.1),col=2)
plot(t,y,xlab="Hour ", ylab="Intensity(%) ", pch=16, xlim = c(-10,80000),ylim = c(-10,120))
lines(x,f5(x,a5.1),col=2)
```

**Second Partial Derivative**

$\frac{\partial^2{l_5}}{\partial{a_1^2}} = \sum_i^{44}((t_ie^{-0.00005t_i})^2$

# Function 6

We now consider the function $$f_6(t; a_1,
a_2) = 100 + a_1t + a_2(1 - e^{-0.0003t})$$. The loglikelihood function we previously computed to be: $$\ell_6(a_1,a_2; \mathbf{t},\mathbf{y}) =
44\ln\left(\frac{1}{\sqrt{2\pi}}\right) - \frac{1}{2}\sum_{i=1}^{44}
(y_i - 100 - a_1t_i - a_2(1 - e^{-0.0003t_i}))^2.$$

We will now apply the maximum likelihood method (assuming the errors are normally distributed) to identify the best fit parameters for this model using the data from our seed. Let’s first load the data, using the code below.

To find the critical values of $\ell_6$ we need to solve the system of linear equations obtained by setting each partial derivative equal to zero, which means we must solve the system

$$\left\{
\begin{align*}
\left(\sum_{i=1}^{44} (y_i - 100)t_i\right) -
\left(\sum_{i=1}^{44}t_i^2\right)a_1 - \left(\sum_{i=1}^{44}t_i(1 -
e^{-0.0003t_i})\right)a_2 &= 0 \\
\left(\sum_{i=1}^{44} (y_i - 100)(1 - e^{-0.0003t_i})\right) -
\left(\sum_{i=1}^{44}t_i(1 - e^{-0.0003t_i})\right)a_1 -
\left(\sum_{i=1}^{44}(1 - e^{-0.0003t_i})^2\right)a_2 &= 0.
\end{align*}
\right.$$

Once again we notice this system of equation is of the form

$$\left\{
\begin{align*}
b_1 - c_{11}a_1 - c_{12}a_2 &= 0 \\
b_2 - c_{21}a_1 - c_{22}a_2 &= 0.
\end{align*}
\right.$$

where $$\sum_{i=1}^{44} (y_i
- 100)t_i$$, $\sum_{i=1}^{44}t_i^2$, $\sum_{i=1}^{44}(1 - e^{-0.0003t_i})^2$, $\sum_{i=1}^{44} (y_i - 100)(1 - e^{-0.0003t_i})$, and $\sum_{i=1}^{44}(1 - e^{-0.0003t_i})^2$ are just constants that depend on the given data. Again we can calculate (and store) their values using R, as well as solve the system, using the code below.

```{r}
c.11 <- sum(t^2)
c.12 <- sum(t*(1-exp(-0.0003*t)))
c.22 <- sum((1-exp(-0.0003*t))^2)
b.1 <- sum((y-100)*t)
b.2 <- sum((y-100)*(1-exp(-0.0003*t)))

best.a2 <- (c.11*b.2 - c.12*b.1)/(c.11*c.22 - c.12^2) 
best.a1 <- (b.1 - c.12*best.a2)/c.11 

pander::pander(paste0("This is the best value for $a_1$: ", best.a1))
pander::pander(paste0("This is the best value for $a_2$: ", best.a2))
```

To finish the maximum likelihood method, we now use the second derivative test. The second partials of $\ell_6$ are:

-   $$\frac{\partial^2 \ell_6}{a_1^2} = -
    \sum_{i=1}^{44}t_i^2$$

-   $$\frac{\partial^2 \ell_6}{a_2^2} = -
    \sum_{i=1}^{44}(1-e^{-0.0003t_i})^2$$

-   $$\frac{\partial^2\ell_6}{\partial a_2
    \partial a_1} = -\sum_{i=1}^{44}t_i(1-e^{-0.0003t_i})$$

The code below uses R to compute:

$$\begin{align*}
D
&= \left(\frac{\partial^2\ell_6}{\partial a_1^2}\right)\left(
\frac{\partial^2\ell_6}{\partial a_2^2}\right) -
\left(\frac{\partial^2\ell_6}{\partial a_2 \partial a_1}\right)^2 \\
&= \left(-\sum_{i=1}^{44}t_i\right)\left(-
\sum_{i=1}^{44}(1-e^{-0.0003t_i})^2\right) -
\left(-\sum_{i=1}^{44}t_i(1-e^{-0.0003t_i})\right)^2
\end{align*}$$ and $\frac{\partial^2\ell_6}{\partial a_1^2}$

```{r}
D <- (-c.11)*(-c.22) - (-c.12)^2
pander::pander(paste0("This is the value for D: ", D))
pander::pander(paste0("The second partial with respect to $a_1$ twice: ", -c.11))
```

Because $$D = 7.3001831\times
10^{7}>0$$ and $$\frac{\partial^2\ell_2}{\partial a_1^2} =
-3.2876753\times 10^{8}<0$$, we know that our critical point corresponds to a local maximum (by the second derivative test). The completes the computations for the maximum likelihood method.

Our best fit model is:

$$f_6(t) = 100 +
(-0.000658665767730825)t +(4.76933030173676)(1 - e^{-0.0003t})$$ where $t \ge 0$. Let's confirm this fit visually with the following R code.

```{r}
f6 <- function(x,a0=100,a1=0,a2=1){
  a0 + a1*x + a2*(1-exp(-0.0003*x))
}

a0 <- 100
a1 <- best.a1
a2 <- best.a2

x <- seq(-10,80001,2)
par(mfrow=c(1,2),mar=c(2.5,2.5,1,0.25))
plot(t,y,xlab="Hour ", ylab="Intensity(%) ", pch=16,main='f6')
lines(x,f6(x,a0,a1,a2),col=2)
plot(t,y,xlab="Hour ", ylab="Intensity(%) ", pch=16, xlim = c(-10,80000),ylim = c(-10,120))
lines(x,f6(x,a0,a1,a2),col=2)
```

The figure above verifies that our fitted function does indeed provide a good visual fit for the model. For this model, the light bulb will burn out (hit 80% intensity) somewhere around 30,000 hours (again uniroot can find this time exactly).
:::
