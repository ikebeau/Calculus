---
title: "Task 3"
format: 
  html:
    code-fold: true
    embed-resources: true
execute: 
  warning: false
editor: visual
---

# Maximum Likelihoods

```{r}
library(data4led)

bulb <- led_bulb(1,seed=719) 
t <- bulb$hours
y <- bulb$percent_intensity

c.11 <- sum(t^2)
c.12 <- sum(t^3)
c.22 <- sum(t^4)
b.1 <- sum((y-100)*t)
b.2 <- sum((y-100)*t^2)
```

## Base Assumptions

These model are intended to predict the decay of light bulb brightness overtime. The decay is measured by a percentage of the original brightness of the light bulb. A light bulb is considered bad after the bulb intensity is at 80% of its original value. There are 44 points within the data set $t_i$ is represented as the number of hours that the light bulb has been on. $y_i$ is a percentage of the light bulbs original intensity. The values used in this analysis are found in the data4led package within R utilizing the seed 719.

For this analysis the assumption that the residuals are independent and normally distributed (with a mean of 0 and a standard deviation of 1) will be applied.

```{r}
pander::pander(data.frame("Function" = c("$f_1$", "$f_2$", "$f_4$", "$f_5$", "$f_6$"), "Equation" = c("$100 + 0.000204780548320951t$ where $t \ge 0$", "$f_2(t) = 100 +
(0.000641522798405015)t +(-1.1442406838189 * 10^{-7})t^2$", "$100 +  (-0.000205194652371931) t + 0.489543302990463 *  ln(0.005t + 1)$", "$100 * e^{-0.00005t} + 0.00574982239530443t e^{-0.0005t}$", "$f_6(t) = 100 + (-0.000658665767730825)t +(4.76933030173676)(1 - e^{-0.0003t})$ ")))
```

</br>

::: panel-tabset
# Function 1

**Base Function**

The function $f_1()$ is defined as: $f_1(t; a_1) = 100 + a_1t$ where $t\geq0$.

**Log Likelihood**

The loglikelihood function for the errors of this model is: $$\ell_1(a_1; \mathbf{t},\mathbf{y}) =
44\ln\left(\frac{1}{\sqrt{2\pi}}\right) - \frac{1}{2}\sum_{i}^{44} (y_i
- 100 - a_1t_i)^2$$.

**First Partial Derivative**

$\frac{\partial{l_1}}{\partial{a_1}} = (\sum^{44}_it_i(y_i-100)) - (\sum^{44}_it_i^2)a_1$

*Note: The results are below the explanation*

We first need to find the answer for each of these $(\sum^{44}_it_i(y_i-100))$ & $- (\sum^{44}_it_i^2)$. For simplicity I will refer to them in the explanation as c & d respectively. The first derivative will be set to 0 to find the value for $a_1$. The equation will be $0 = c - d * a_1$. After this you solve for $a_1$ ending with an equation like so $\frac{-c}{d} = a_1$.

```{r}
c.l1.11 <- sum(t*(y-100))
c.l1.12 <- -sum(t^2)
a.1 <- -c.l1.11/c.l1.12


pander::pander(paste0("This is the value for part c: ", c.l1.11))
pander::pander(paste0("This is the value for part d: ", c.l1.12))
pander::pander(paste0("This is the best value for $a_1$ ", a.1))

x <- seq(-10,80001,2)

f1 <- function(x=x,a1=a.1){
  y.p <- 100 + a1 * x
  return(y.p)
}


```

```{r}
y.p <- f1(x, a.1)
```

```{r}
par(mfrow=c(1,2),mar=c(2.5,2.5,1,0.25))
plot(t,y,xlab="Hour ", ylab="Intensity(%) ", pch=16,main='f1')
lines(x,f1(x, a.1),col=2)
plot(t,y,xlab="Hour ", ylab="Intensity(%) ", pch=16, xlim = c(-10,80000),ylim = c(-10,120))
lines(x,f1(x,a.1),col=2)
```

**Second Partial Derivative**

$\frac{\partial^2{l_1}}{\partial{a_1^2}} = - \sum_i^{44}t^2_i$

# Function 2

Consider the model $f_2(t; a_1, a_2) = 100 + a_1t + a_2t^2$. The function $f_2$ models the brightness of a lightbulb, measured as a percent of the original intensity of the lightbulb, given the number of hours the lightbulb as been on, t. We will fit $f_2$to the list of 44 measurements, (ti,yi), obtained from the data4led package using the seed 719.

Assuming the residuals (or errors) are independent and normally distributed (with mean 0 and standard deviation 1), the loglikelihood function for these errors is

$\ell_2(a_1,a_2; \mathbf{t},\mathbf{y}) = 44\ln\left(\frac{1}{\sqrt{2\pi}}\right) + \sum_{i=1}^{44} \left(-\frac{1}{2}(y_i - 100 - a_1t_i - a_2t_i^2)^2\right).$

We want to find the maximum of $\ell_2$. The first partials of $\ell_2$ are

-   $$\frac{\partial\ell_2}{\partial a_1} =
    \left(\sum_{i=1}^{44} (y_i - 100)t_i\right) -
    \left(\sum_{i=1}^{44}t_i^2\right)a_1 -
    \left(\sum_{i=1}^{44}t_i^3\right)a_2$$ and
-   $$\frac{\partial\ell_2}{\partial a_2} =
    \left(\sum_{i=1}^{44} (y_i - 100)t_i^2\right) -
    \left(\sum_{i=1}^{44}t_i^3\right)a_1 -
    \left(\sum_{i=1}^{44}t_i^4\right)a_2$$

To find the critical points of $\ell_2$, we set each partial derivative above equal to zero and then solve

$$\left\{
\begin{array}{ll}
\left(\sum_{i=1}^{44} (y_i - 100)t_i\right) -
\left(\sum_{i=1}^{44}t_i^2\right)a_1 -
\left(\sum_{i=1}^{44}t_i^3\right)a_2 &= 0 \\
\left(\sum_{i=1}^{44} (y_i - 100)t_i^2\right) -
\left(\sum_{i=1}^{44}t_i^3\right)a_1 -
\left(\sum_{i=1}^{44}t_i^4\right)a_2 &= 0.
\end{array}
\right.$$

We notice that this system is of the form:

$$\left\{
\begin{align*}
b_1 - c_{11}a_1 - c_{12}a_2 &= 0 \\
b_2 - c_{21}a_1 - c_{22}a_2 &= 0,
\end{align*}
\right.$$

with:

-   $$c_{11} =
    \sum_{i=1}^{44}t_i^2$$

-   $$c_{12} = c_{21} = \sum_{i=1}^{44}
    t_i^3$$

-   $$c_{22} = \sum_{i=1}^{44}
    t_i^4$$

-   $$b_1 = \sum_{i=1}^{44} (y_i -
    100)t_i$$

-   $$b_2 = \sum_{i=1}^{44} (y_i -
    100)t_i^2$$

Notice that $$\sum_{i=1}^{44} (y_i -
100)t_i$$, $\sum_{i=1}^{44}t_i^2$, $\sum_{i=1}^{44} t_i^3$, $\sum_{i=1}^{44} (y_i - 100)t_i^2$, and $\sum_{i=1}^{44} t_i^4$ are just constants that depend on the given data. We can calculate (and store) their values using the R code below.

```{r}
c.11 <- sum(t^2)
c.12 <- sum(t^3)
c.22 <- sum(t^4)
b.1 <- sum((y-100)*t)
b.2 <- sum((y-100)*t^2)
```

Since we noticed this system is of a general form we have already solved, then we can use the solution from previous work. We found that the solution to this system is

$$a_2 =
\frac{c_{11}b_2 - c_{12}b_1}{c_{11}c_{22} - c_{12}^2}\text{ and }a_1 =
\frac{b_1 - c_{12}a_2}{c_{11}}.$$ and $$a_2 =
\frac{c_{11}b_2 - c_{12}b_1}{c_{11}c_{22} - c_{12}^2}\text{ and }a_1 =
\frac{b_1 - c_{12}a_2}{c_{11}}.$$

Below we use R to calculate $a_1$ and $a_2$ using the formula above.

```{r}
best.a2 <- (c.11*b.2 - c.12*b.1)/(c.11*c.22 - c.12^2) 
best.a1 <- (b.1 - c.12*best.a2)/c.11 
pander::pander(paste0("This is the best value for $a_1$:", best.a1))
pander::pander(paste0("This is the best value for $a_2$:", best.a2))
```

The critical point for $\ell_2$ is $(a_1,a_2) = (0.000641522798405015, -1.1442406838189 \times 10^{-7}$. Letâ€™s use the second derivative test to confirm that this critical point is the location of a maximum of $\ell_2$. The second partials of $\ell_2$are below. We will need the second partials for the second derivative test.

-   $$\frac{\partial^2\ell_2}{\partial a_1^2}
    = - \sum_{i=1}^{44}t_i^2$$

-   $$\frac{\partial^2\ell_2}{\partial a_2^2}
    = - \sum_{i=1}^{44}t_i^4$$

-   $$\frac{\partial^2\ell_2}{\partial a_2
    \partial a_1} = -\sum_{i=1}^{44}t_i^3$$

When then compute

$$D =
\left(\frac{\partial^2\ell_2}{\partial a_1^2}\right)\left(
\frac{\partial^2\ell_2}{\partial a_2^2}\right) -
\left(\frac{\partial^2\ell_2}{\partial a_2 \partial a_1}\right)^2 =
\left(- \sum_{i=1}^{44}t_i^2\right)\left(- \sum_{i=1}^{44}t_i^4\right) -
\left(- \sum_{i=1}^{44}t_i^3\right)^2.$$

To use the second derivative test, we need numerical values for both D and $\frac{\partial^2\ell_2}{\partial a_1^2}$. The code below computes both these values.

```{r}
D <- (-c.11)*(-c.22) - (-c.12)^2
pander::pander(paste0("This is the value for D:", D))
pander::pander(paste0("The second partial with respect to $a_1$ twice:", -c.11))

```

We see that $D = 1.23002961725515 \times 10^{23}$, which means D \> 0. The fact that D \> 0, together with $$\frac{\partial^2\ell_2}{\partial a_1^2} =
-3.2876753\times 10^{8}<0$$ means that our critical point corresponds to a local maximum (by the second derivative test). The completes the computations for the maximum likelihood method.

Our best fit model is

$$f_2(t) = 100 +
(0.000641522798405015)t +(-1.1442406838189\times 10^{-7})t^2$$

```{r}
f2 <- function(x,a0=0,a1=0,a2=1){
  a0 + a1*x + a2*x^2
}

a0 <- 100
a1 <- best.a1
a2 <- best.a2

x <- seq(-10,80001,2)
par(mfrow=c(1,2),mar=c(2.5,2.5,1,0.25))
plot(t,y,xlab="Hour ", ylab="Intensity(%) ", pch=16,main='f2')
lines(x,f2(x,a0,a1,a2),col=2)
plot(t,y,xlab="Hour ", ylab="Intensity(%) ", pch=16, xlim = c(-10,80000),ylim = c(-10,120))
lines(x,f2(x,a0,a1,a2),col=2)
```

Notice that the graph of the fitted function does appear to provide a good visual fit to the data, as seen in the image above. The story told by this model suggests that the light bulb will burn out (hit 80% intensity) somewhere between 10 and 20 thousand hours (we could compute this exactly with uniroot).

# Function 4

The function $f_4$ is defined as: $f_4(t; a_1,a_2) = 100 + a_1t + a_2\ln(0.005t+1)$ where $t\geq0$.

**Log Likelihood**

The loglikelihood function for the errors of this model is: $$\ell_4(a_1,a_2; \mathbf{t},\mathbf{y}) =
44\ln\left(\frac{1}{\sqrt{2\pi}}\right) - \frac{1}{2}\sum_{i}^{44} (y_i
- 100 - a_1t_i - a_2\ln(0.005t_i+1))^2$$.

**Derivatives**

::: panel-tabset
### Partial Derivatives $a_1$

**This is the first partial derivative**

$\frac{\partial{l_4}}{\partial{a_1}} = \sum_i^{44}t_i(y_i-100) - (\sum^{44}_it_i^2)a_1 - (\sum_i^{44}t_i(ln(0.00005t_i + 1)))a_2$

**This is the second partial derivative**

$\frac{\partial^2{l_4}}{\partial{a_1^2}} = -(\sum^{44}_it_i^2)$

### Partial Derivatives $a_2$

**This is the first partial derivative**

$\frac{\partial{l_4}}{\partial{a_2}} = (\sum_i^{44}(y_i-100)ln(0.0005t_i +1)) - (\sum^{44}_i t_i ln(0.0005t_i + 1))a_1 - (\sum(ln(0.0005t_i + 1))^2)a_2$

**This is the second partial derivative**

$\frac{\partial^2{l_4}}{\partial{a_2^2}} = - \sum^{44}_i(ln(0.0005t_i + 1))^2$

### Systems of Equations

For this section we will use the first derivatives with respect to $a_1$ and the first for $a_2$ respectively. Below each has been rephrased:

**For** $a_1$

$\frac{\partial{l_4}}{\partial{a_1}} = \sum_i^{44}t_i(y_i-100) - (\sum^{44}_it_i^2)a_1 - (\sum_i^{44}t_i(ln(0.0005t_i + 1)))a_2$

**For** $a_2$

$\frac{\partial{l_4}}{\partial{a_2}} = (\sum_i^{44}(y_i-100)ln(0.0005t_i +1)) - (\sum^{44}_i t_i ln(0.0005t_i + 1))a_1 - (\sum(ln(0.0005t_i + 1))^2)a_2$

For both $a_1$ and $a_2$'s first derivative we will assume each constant to be b, c (with different numeric values to differentiate) respectively. So for each equation it could be rewritten as:

$$\left\{
\begin{align*}
0 = b_1 - c_{11}*a_1 - c_{12}*a_2 \\
0 = b_2 - c_{21}*a_1 - c_{22} *a_2
\end{align*}
\right.$$

where

-   $b_1 = \sum_i^{44}t_i(y_i-100)$
-   $b_2 = (\sum_i^{44}(y_i-100)ln(0.0005t_i +1))$
-   $c_{11} = - (\sum^{44}_it_i^2)$
-   $c_{12} = - (\sum_i^{44}t_i(ln(0.0005t_i + 1)))$
-   $c_{21} = - (\sum^{44}_i t_i ln(0.0005t_i + 1))$
-   $c_{22} = - (\sum(ln(0.0005t_i + 1))^2)$

In order to find the $a_1$ & $a_2$ we can use this formula:

$a_2 =\frac{c_{11}b_2 - c_{12}b_1}{c_{11}c_{22} - c_{12}^2}\text{ and }a_1 =\frac{b_1 - c_{12}a_2}{c_{11}}$

```{r}
b.1 <- sum(t * (y - 100))
b.2 <- sum((y - 100) * log(0.005*t + 1))
c.11 <- - sum(t^2)
c.12 <- - sum(t * log(0.005 * t + 1))
c.21 <- - sum(t * log(0.005 * t + 1))
c.22 <- - sum((log(0.005 * t + 1))^2)

a2.4 <- ((c.11 * b.2) - (c.12 * b.1))/((c.11 * c.22) - (c.12^2))
a1.4 <- (b.1 - (c.12 * a2.4))/(c.11)
a1.4 <- -a1.4
a2.4 <- -a2.4

paste0("This is the best value for $a_1$:", a1.4)
paste0("This is the best value for $a_2$:", a2.4)

f4 <- function(x, a1.4, a2.4){
  y4.p <- (100 + (a1.4 * x) + (a2.4 * log((0.005 * x) + 1)))
  return(y4.p)
}

```

```{r}
par(mfrow=c(1,2),mar=c(2.5,2.5,1,0.25))
plot(t,y,xlab="Hour ", ylab="Intensity(%) ", pch=16,main='f4')
lines(x,f4(x, a1.4, a2.4),col=2)
plot(t,y,xlab="Hour ", ylab="Intensity(%) ", pch=16, xlim = c(-10,80000),ylim = c(-10,120))
lines(x,f4(x,a1.4, a2.4),col=2)
```
:::

# Function 5

The function $f_5$ is defined as: $f_5(t; a_1) = 100e^{-0.00005t} +a_1te^{-0.00005t}$ where $t\geq0$.

**Log Likelihood**

The log likelihood function for the errors of this model is: $$\ell_5(a_1; \mathbf{t},\mathbf{y}) =
44\ln\left(\frac{1}{\sqrt{2\pi}}\right) - \frac{1}{2}\sum_{i}^{44} (y_i
- 100e^{-0.00005t_i} - a_1t_ie^{-0.00005t_i})^2$$

**First Partial Derivative**

$\frac{\partial{l_5}}{\partial{a_1}} = \sum_i^{44}((y_i - 100 e^{-0.00005t_i})(t_ie^{-0.00005t_i})) - (\sum^{44}_i(t_ie^-0.00005t_i)^2)a_1$

We first need to find the answer for each of these $\sum_i^{44}((y_i - 100 e^{-0.00005t_i})(t_ie^{-0.00005t_i}))$ & $- (\sum^{44}_i(t_ie^-0.00005t_i)^2)a_1$. For simplicity I will refer to them in the explanation as c & d respectively. The first derivative will be set to 0 to find the value for $a_1$. The equation will be $0 = c - d * a_1$. After this you solve for $a_1$ ending with an equation like so $\frac{-c}{d} = a_1$.

```{r}
c.l5.11 <- sum((y - 100 * exp(-0.00005*t)) * (t*exp(-0.00005 * t)))
c.l5.12 <- -sum((t*exp((-0.00005*t)))^2)
a5.1 <- -c.l5.11/c.l5.12


pander::pander(paste0("This is the value for part c: ", c.l5.11))
pander::pander(paste0("This is the value for part d: ", c.l5.12))
pander::pander(paste0("This is the best value for $a_1$ ", a5.1))

x <- seq(-10,80001,2)

f5 <- function(x=x,a1=a5.1){
  y.p <- (100*exp(-0.00005*x)) + (a5.1 * x * exp(-0.00005*x))
  return(y.p)
}
```

```{r}
par(mfrow=c(1,2),mar=c(2.5,2.5,1,0.25))
plot(t,y,xlab="Hour ", ylab="Intensity(%) ", pch=16,main='f1')
lines(x,f5(x, a5.1),col=2)
plot(t,y,xlab="Hour ", ylab="Intensity(%) ", pch=16, xlim = c(-10,80000),ylim = c(-10,120))
lines(x,f5(x,a5.1),col=2)
```

**Second Partial Derivative**

$\frac{\partial^2{l_5}}{\partial{a_1^2}} = \sum_i^{44}((t_ie^{-0.00005t_i})^2$

# Function 6

We now consider the function $$f_6(t; a_1,
a_2) = 100 + a_1t + a_2(1 - e^{-0.0003t})$$. The loglikelihood function we previously computed to be: $$\ell_6(a_1,a_2; \mathbf{t},\mathbf{y}) =
44\ln\left(\frac{1}{\sqrt{2\pi}}\right) - \frac{1}{2}\sum_{i=1}^{44}
(y_i - 100 - a_1t_i - a_2(1 - e^{-0.0003t_i}))^2.$$

We will now apply the maximum likelihood method (assuming the errors are normally distributed) to identify the best fit parameters for this model using the data from our seed. Letâ€™s first load the data, using the code below.

To find the critical values of $\ell_6$ we need to solve the system of linear equations obtained by setting each partial derivative equal to zero, which means we must solve the system

$$\left\{
\begin{align*}
\left(\sum_{i=1}^{44} (y_i - 100)t_i\right) -
\left(\sum_{i=1}^{44}t_i^2\right)a_1 - \left(\sum_{i=1}^{44}t_i(1 -
e^{-0.0003t_i})\right)a_2 &= 0 \\
\left(\sum_{i=1}^{44} (y_i - 100)(1 - e^{-0.0003t_i})\right) -
\left(\sum_{i=1}^{44}t_i(1 - e^{-0.0003t_i})\right)a_1 -
\left(\sum_{i=1}^{44}(1 - e^{-0.0003t_i})^2\right)a_2 &= 0.
\end{align*}
\right.$$

Once again we notice this system of equation is of the form

$$\left\{
\begin{align*}
b_1 - c_{11}a_1 - c_{12}a_2 &= 0 \\
b_2 - c_{21}a_1 - c_{22}a_2 &= 0.
\end{align*}
\right.$$

where $$\sum_{i=1}^{44} (y_i
- 100)t_i$$, $\sum_{i=1}^{44}t_i^2$, $\sum_{i=1}^{44}(1 - e^{-0.0003t_i})^2$, $\sum_{i=1}^{44} (y_i - 100)(1 - e^{-0.0003t_i})$, and $\sum_{i=1}^{44}(1 - e^{-0.0003t_i})^2$ are just constants that depend on the given data. Again we can calculate (and store) their values using R, as well as solve the system, using the code below.

```{r}
c.11 <- sum(t^2)
c.12 <- sum(t*(1-exp(-0.0003*t)))
c.22 <- sum((1-exp(-0.0003*t))^2)
b.1 <- sum((y-100)*t)
b.2 <- sum((y-100)*(1-exp(-0.0003*t)))

best.a2 <- (c.11*b.2 - c.12*b.1)/(c.11*c.22 - c.12^2) 
best.a1 <- (b.1 - c.12*best.a2)/c.11 

pander::pander(paste0("This is the best value for $a_1$: ", best.a1))
pander::pander(paste0("This is the best value for $a_2$: ", best.a2))
```

To finish the maximum likelihood method, we now use the second derivative test. The second partials of $\ell_6$ are:

-   $$\frac{\partial^2 \ell_6}{a_1^2} = -
    \sum_{i=1}^{44}t_i^2$$

-   $$\frac{\partial^2 \ell_6}{a_2^2} = -
    \sum_{i=1}^{44}(1-e^{-0.0003t_i})^2$$

-   $$\frac{\partial^2\ell_6}{\partial a_2
    \partial a_1} = -\sum_{i=1}^{44}t_i(1-e^{-0.0003t_i})$$

The code below uses R to compute:

$$\begin{align*}
D
&= \left(\frac{\partial^2\ell_6}{\partial a_1^2}\right)\left(
\frac{\partial^2\ell_6}{\partial a_2^2}\right) -
\left(\frac{\partial^2\ell_6}{\partial a_2 \partial a_1}\right)^2 \\
&= \left(-\sum_{i=1}^{44}t_i\right)\left(-
\sum_{i=1}^{44}(1-e^{-0.0003t_i})^2\right) -
\left(-\sum_{i=1}^{44}t_i(1-e^{-0.0003t_i})\right)^2
\end{align*}$$ and $\frac{\partial^2\ell_6}{\partial a_1^2}$

```{r}
D <- (-c.11)*(-c.22) - (-c.12)^2
pander::pander(paste0("This is the value for D: ", D))
pander::pander(paste0("The second partial with respect to $a_1$ twice: ", -c.11))
```

Because $$D = 7.3001831\times
10^{7}>0$$ and $$\frac{\partial^2\ell_2}{\partial a_1^2} =
-3.2876753\times 10^{8}<0$$, we know that our critical point corresponds to a local maximum (by the second derivative test). The completes the computations for the maximum likelihood method.

Our best fit model is:

$$f_6(t) = 100 +
(-0.000658665767730825)t +(4.76933030173676)(1 - e^{-0.0003t})$$ where $t \ge 0$. Let's confirm this fit visually with the following R code.

```{r}
f6 <- function(x,a0=100,a1=0,a2=1){
  a0 + a1*x + a2*(1-exp(-0.0003*x))
}

a0 <- 100
a1 <- best.a1
a2 <- best.a2

x <- seq(-10,80001,2)
par(mfrow=c(1,2),mar=c(2.5,2.5,1,0.25))
plot(t,y,xlab="Hour ", ylab="Intensity(%) ", pch=16,main='f6')
lines(x,f6(x,a0,a1,a2),col=2)
plot(t,y,xlab="Hour ", ylab="Intensity(%) ", pch=16, xlim = c(-10,80000),ylim = c(-10,120))
lines(x,f6(x,a0,a1,a2),col=2)
```

The figure above verifies that our fitted function does indeed provide a good visual fit for the model. For this model, the light bulb will burn out (hit 80% intensity) somewhere around 30,000 hours (again uniroot can find this time exactly).
:::
